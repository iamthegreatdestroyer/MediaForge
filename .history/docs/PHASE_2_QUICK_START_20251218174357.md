# Phase 2 Quick Start Guide - AI-Native Features

**Status:** Ready to begin implementation  
**Timeline:** 2-3 weeks for MVP  
**Hardware:** Windows 11 + Ollama (already installed)

---

## ðŸš€ Immediate Setup (30 minutes)

### Step 1: Verify Ollama Installation

```powershell
# Check Ollama is running
curl http://localhost:11434/api/tags

# Should return list of models, e.g.:
# {"models":[{"name":"ollama:latest",...}]}
```

âœ… **Your Ollama path:** `C:\Users\sgbil\.ollama\models`

### Step 2: Pull Recommended Models

```powershell
# Start PowerShell as Admin (if needed)

# Pull lightweight embeddings model (~24MB) - FASTEST
ollama pull all-minilm-l6-v2

# Pull Phi-4-mini for tagging (~2.4GB) - BEST FOR TAGGING
ollama pull phi4:4b

# (Optional) Pull Mistral for comparison (~4GB)
ollama pull mistral:7b

# Verify models loaded
ollama list
```

**Expected output:**
```
NAME                      ID              SIZE    MODIFIED
all-minilm-l6-v2          d0d8e8ccd130    24 MB   2 days ago
phi4:4b                   8c17dfef5e36    2.4 GB  1 day ago
mistral:7b                40e2bad04951    4.0 GB  3 days ago
```

â±ï¸ **Time**: ~15-20 minutes (depends on internet speed)

### Step 3: Install Python Dependencies

```powershell
cd C:\Users\sgbil\MediaForge

# Activate venv
.\.venv\Scripts\Activate.ps1

# Install AI stack
pip install -e .[ml-tier1]

# Verify installations
python -c "import ollama; import sentence_transformers; import hdbscan; print('âœ… All dependencies installed')"
```

**What gets installed:**
- `ollama` - Ollama Python client
- `sentence-transformers` - Embeddings
- `scikit-learn` - Clustering
- `scikit-learn` - HDBSCAN
- `umap-learn` - Dimensionality reduction
- `opencv-python` - Image processing

### Step 4: Update Core Exports

**File:** `src/core/__init__.py`

Add these imports:
```python
from .ai_engine import AIEngine, get_ai_engine, is_ai_available
from .semantic_search import SemanticSearchEngine, get_search_engine
```

### Step 5: Quick Test

```powershell
# Test AI Engine
python -c "
from src.core.ai_engine import get_ai_engine

engine = get_ai_engine()
print(f'âœ… AI Engine ready: {engine.is_available()}')

# Test embeddings
texts = ['nature documentary', 'sunset landscape']
embeddings = engine.generate_embeddings(texts)
print(f'âœ… Embeddings generated: shape={embeddings.shape}')
"
```

---

## ðŸ“ Implementation Roadmap

### Week 1: Core Infrastructure

**Day 1-2: AI Engine**
- âœ… `src/core/ai_engine.py` (CREATED)
- Ollama integration
- Embeddings generation
- Tag generation
- Image analysis

**Day 3-4: Semantic Search**
- âœ… `src/core/semantic_search.py` (CREATED)
- Query embedding
- Similarity search
- UMAP clustering
- HDBSCAN clustering

**Day 5: Database Updates**
- Add embedding columns to MediaItem
- Create embedding indexes
- Add tag storage

### Week 2: Integration & APIs

**Day 1-2: Auto-Tagger**
- `src/core/auto_tagger.py` (NEW)
- Batch processing
- Incremental tagging
- Integration with scanner

**Day 3-4: REST APIs**
- `src/api/routers/search.py` (NEW)
- Semantic search endpoint
- Tag generation endpoint
- Collections endpoint

**Day 5: CLI Commands**
- `src/cli/commands/ai.py` (NEW)
- `mediaforge ai tag` command
- `mediaforge search --semantic` command
- `mediaforge collections` command

### Week 3: Testing & Optimization

**Day 1-2: Unit Tests**
- Test AI engine components
- Test search functionality
- Test clustering

**Day 3-4: Integration Tests**
- End-to-end workflows
- Performance benchmarks
- Database persistence

**Day 5: Documentation**
- User guides
- API documentation
- Performance tips

---

## ðŸŽ¯ Key Features to Implement

### Auto-Tagging
```python
# CLI Usage:
mediaforge ai tag --media-id 123
mediaforge ai tag --all --use-visual

# API:
POST /api/v1/ai/tags?media_id=123
GET /api/v1/media/123/tags
```

### Semantic Search
```python
# CLI Usage:
mediaforge search --semantic "sunset landscape" --top-k 20

# API:
GET /api/v1/search/semantic?q=sunset%20landscape&top_k=20
```

### Auto-Collections
```python
# CLI Usage:
mediaforge collections discover

# API:
GET /api/v1/collections/auto?min_size=3
```

---

## ðŸ“Š Performance Expectations

| Operation | Speed | Hardware |
|-----------|-------|----------|
| Embedding text | 10-100ms | CPU |
| Generate tags (Phi-4) | 300-1000ms | CPU |
| Analyze image | 1-10s | CPU |
| Semantic search (1K items) | 50-200ms | CPU |
| UMAP + HDBSCAN (1K items) | 2-10s | CPU |

**Note:** Speeds will improve significantly if GPU is available

---

## ðŸ”§ Dependencies to Add to pyproject.toml

```toml
[project.optional-dependencies]
ml-tier1 = [
    "ollama>=0.1.0",              # Ollama client
    "sentence-transformers>=2.2", # Embeddings
    "scikit-learn>=1.3",          # Clustering tools
    "hdbscan>=0.8",               # Clustering algorithm
    "umap-learn>=0.5",            # Dimensionality reduction
    "opencv-python>=4.8",         # Image processing
    "numpy>=1.24",
    "scipy>=1.10",
]

ml-full = ["mediaforge[ml-tier1]"]
```

---

## âœ… Pre-Implementation Checklist

- [x] Ollama installed at `C:\Users\sgbil\.ollama\models`
- [ ] Models pulled (all-minilm-l6-v2, phi4:4b)
- [ ] Dependencies installed (`pip install -e .[ml-tier1]`)
- [ ] Core modules created (ai_engine.py, semantic_search.py)
- [ ] `src/core/__init__.py` updated with new exports
- [ ] Database schema ready for embeddings
- [ ] Tests are ready to run

---

## ðŸ“‹ Files to Create (In Order)

### Week 1
1. âœ… `src/core/ai_engine.py` - Core AI engine (DONE)
2. âœ… `src/core/semantic_search.py` - Search engine (DONE)
3. `alembic/versions/0002_add_ai_features.py` - Database migrations
4. `src/core/auto_tagger.py` - Auto-tagging service

### Week 2
5. `src/api/routers/search.py` - Search endpoints
6. `src/cli/commands/ai.py` - CLI commands
7. `tests/unit/test_ai_engine.py` - Unit tests
8. `tests/unit/test_semantic_search.py` - Search tests

### Week 3
9. Documentation and guides

---

## ðŸŽ“ Learning Resources

**Model Documentation:**
- [Ollama Library](https://ollama.ai/library)
- [Sentence Transformers](https://www.sbert.net/)
- [HDBSCAN](https://hdbscan.readthedocs.io/)
- [UMAP](https://umap-learn.readthedocs.io/)

**Integration Examples:**
- Ollama Python: `from ollama import Client`
- SentenceTransformers: `from sentence_transformers import SentenceTransformer`
- Clustering: `from sklearn.metrics.pairwise import cosine_similarity`

---

## ðŸš¨ Troubleshooting

### Ollama Not Connecting
```powershell
# Check Ollama is running
Get-Process ollama

# Restart Ollama
Stop-Process -Name ollama
Start-Process ollama
```

### Out of Memory
- Use smaller models: `phi4:4b` instead of `phi4`
- Process in batches: 5-10 items at a time
- Clear cache: `ollama rm MODEL_NAME`

### Slow Performance
- GPU acceleration: Install `onnxruntime[gpu]`
- Batch processing: Multiple items at once
- Model quantization: Use GGUF quantized versions

---

## ðŸ“ž Next Steps

**Before you proceed:**

1. Complete the 30-minute setup above
2. Run the quick test to verify everything works
3. Let me know if any issues arise

**Once ready:**

I will begin implementation of:
1. Database schema updates for embeddings
2. Auto-tagging service
3. REST API endpoints
4. CLI commands
5. Integration tests

---

**Ready to begin Phase 2! ðŸš€**

The foundation is set. All core modules are created and ready for integration.
